# Оптимизация работы хэш-таблицы с использованием профилирования

## Аннотация
В данной работе исследуются приемы оптимизации хеш-таблицы, реализованной методом цепочек. Основная цель — выявить «горячие» участки кода с помощью профилирования и улучшить их производительность за счет использования низкоуровневых техник, таких как ассемблерные вставки, `intrinsics`, реализация функций на `nasm`.

Оптимизации будут проводиться итеративно. Всего будет проведено 5 оптимизаций, за каждую из которых отвечает своя версия проекта `VERSION_1`, `VERSION_2`, ... , `VERSION_5`

## Среда и интрументы
* __Процессор:__ Intel Core i5-10300H 2.5GHz
* __Компилятор:__ g++ 13.3.0
* __Среда:__ Ubuntu 24.04
* __Инструменты профилирования:__ perf, hotspot
* __Сборка:__ makefile, python

## Входные данные
Перед началом тестирования хэш таблицы требуется сгенерировать входные данные. В качестве исходника для входных данных был взят текст романа Л. Н. Толстого "Война и мир", находящийся в файле `war_and_peace.txt`.

Подготовленными входными данными являются:
* Список слов для загрузки в хэш таблицу `text.txt`
* Список слов для тестирования хэш таблицы `tests.txt`

Для исследования оптимизаций хэш-таблицы установим:
* Длину каждого списка из входных данных в `40000` слов
* Размер хэш-таблицы в `512` ячеек

Данные константы были подобраны для того, чтобы `load factor` хэш-таблицы был равен `≈15`. В реальности для данное значение `load factor` слишком велико и может привести к длительному линейному поиску в односвязном списке. В данной работе `load factor` был взят неоптимальным специально для возможности применения эффективных оптимизации к функции `strncmp` и достоверного исследования хеш-функции на частоту коллизий.

Для генерации входных данных используйте команду:

```bash
    python3 run.py gen_tests
```

После выполнения команды будет создана папка `data` с файлами `text.txt` и `tests.txt` с необходимыми входными данными.



## Бенчмаркинг версий
Для измерения времени работы всех версий проекта (`VERSION_1` - `VERSION_5`) исполните команду
```bash
    python3 run.py versions_benchmarks <кол-во измерений на версию>
```
По умолчанию кол-во измерений на версию равно 20

После выполнения команды в папке `results` появится папка `versions_benchmark.out` с результатами бенчмаркинга с учетом погрешности ($x_{mean} ± 	\sigma_{x_{mean}}$). При расчете использовались формулы:

$$x_{mean} = \frac{\Sigma_{1}^{N}x_i}{n} $$

$$s = \sqrt{\frac{1}{N - 1}\Sigma_{1}^{N}(x_i - x_{mean})^2}$$

$$\sigma_{x_{mean}} = \frac{s}{\sqrt{N}}$$

$$\sigma_{x_{mean}} = \frac{s}{\sqrt{N}}$$

Рядом с результатом измерения будет выведена информация об абсолютной погрешности:
`(error : XX.XX%)`. Для уменьшения относительной погрешности рекомендуется увеличить `<кол-во измерений на версию>`



## Исследование функций хэширования
Перед началом процесса оптимизации рассмотрим несколько хэш-функций и отберем самую лучшую.
Все хэш-функции имеют сигнатуру
```c++
uint64_t hash_function(char *key_32b, const size_t len);
```
Выбор самой лучшей хэш-функции будет определятся несколькими критериями:
* __Величина стандартного расредления коллизий__. Чем меньше величина, тем равномернее будут распределяться значения по хэш-таблице, что будет способствовать ускорению поиска значений.
* __intrinsic Поддержка__. Для некоторых хэш-функций были созданы `intrinsics`, использование которых значительно ускоряет их работу.

### Хэш-функция : "Первый символ"
Реализация
```c++
uint64_t first_char_hash_func(char *key, const size_t len) {
    return (uint64_t) key[0];
}
```

![image](results/hash_funcs/img/fchar.png)

__Стандартное отклонение__ : 71.08

Функция не покрывает весь диапазон значений. Большинство значений приходятся на промежуток `[50, 130]`. Не смотря на свою большую скорость, функция неэффективна из-за распределения своих значений.


### Хэш-функция : "Полиномиальная"
Реализация
```c++
uint64_t polynom_hash_func(char *key, const size_t len) {
    uint64_t hash = 0;
    for (size_t i = 0; i < len; i++) {
        hash = (hash * 255 + (uint64_t) key[i]) % (1e9 + 7);
    }
    return hash;
}
```
![image](results/hash_funcs/img/poly.png)

__Стандартное отклонение__ : 3.96

Функция достаточно хорошо покрывает весь диапазон значений, но у неё `intrinsic` поддержки.



### Хэш-функция : "FNV (Fowler–Noll–Vo)"

Реализация
```c++
uint64_t fnv1a_hash(char *key, const size_t len) {
    const uint64_t FNV_prime = 0x01000193;
    uint64_t hash = 0x811C9DC5;
    const uint8_t *bytes = (const uint8_t *) key;

    for (size_t i = 0; i < len; i++) {
        hash ^= bytes[i];
        hash *= FNV_prime;
    }
    return hash;
}
```
![image](results/hash_funcs/img/fnv.png)

__Стандартное отклонение__ : 3.92

Хорошая с точки зрения распределения хэш-функция. Есть `intrinsic` поддержка.


### Хэш-функция : "CR32"

Реализация
```c++
uint64_t crc32_hash_func(char *key, const size_t len) {
    const uint64_t CR32_POLY = 0x04C11DB7;
    const unsigned char *buffer = (const unsigned char*) key;
    uint64_t crc = (uint64_t) -1;

    for (size_t i = 0; i < len; i++) {
        crc = crc ^ (uint64_t) (*buffer++ << 24);
        for( int bit = 0; bit < 8; bit++ )
        {
            if( crc & (1L << 31)) crc = (crc << 1) ^ CR32_POLY;
            else                  crc = (crc << 1);
        }
    }

    return ~crc;
}
```
![image](results/hash_funcs/img/cr32.png)

__Стандартное отклонение__ : 3.92

Хорошая с точки зрения распределения хэш-функция. Есть `intrinsic` поддержка.



## Методика профилирования
