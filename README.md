# Оптимизация работы хэш-таблицы с использованием профилирования


## Содержание
- [Аннотация](#аннотация)
- [Среда и инструменты](#среда-и-инструменты)
- [Входные данные](#входные-данные)
- [Исследование функций хэширования](#исследование-функций-хэширования)
- [Бенчмаркинг версий](#бенчмаркинг-версий)

- [Результаты и обсуждение](#результаты-и-обсуждение)
- [Заключение](#заключение)




## Аннотация
Хэш-таблица - это структура данных, позволяющая хранить пары (ключ, значение) и выполнять три операции: операцию добавления новой пары, операцию поиска и операцию удаления пары по ключу.

В данной работе была реализована хэш-таблица с разрешение коллизий с помощью цепочек. Структура таблицы представляет из себя массив односвязных списков, в каждой вершине которого хранятся пары (ключ, значение). В данной работе не используется значение пары, поэтому его нет в структурах.

```c++
// Структура хэш таблицы:

struct list_node_t {
    const char *key;
    list_node_t* next;
};

struct hash_table_32b_t {
    size_t sz;
    hash_function_t hash_function;
    list_node_t **data;
};
```

При добавлении новой пары благодаря хэш-функции ключ преобразуется в индекс массива. При хэшировании ключа возможно возникновение __коллизии__ - ситуации, в которой двум различным ключам сопоставляется одна ячейка массива. В этом случае производится проход по односвязному списку, находящемуся в данной ячейке массива, и явное сравнение ключей вершин списка и добавляемого ключа. При отсутствия совпадения, новая пара добавляется в конец односвязного списка.

```c++
bool hash_table_32b_insert_key(hash_table_32b_t *hash_table, const char key_32b[]) {

    uint64_t table_idx = hash_table->hash_function(key_32b) % hash_table->sz;

    list_node_t *cur_node = hash_table->data[table_idx];
    list_node_t *last_node = NULL;

    while (cur_node) {
        last_node = cur_node;
        if (strncmp(key_32b, cur_node->key, 32) == 0) return true;
        cur_node = cur_node->next;
    }

    list_node_t *new_node = list_node_t_ctor(key_32b);

    if (last_node) last_node->next = new_node;
    else hash_table->data[table_idx] = new_node;

    return true;
}
```

Операции поиска схожа с операцией добавления, за исключением того, что при обнаружении совпадения в проходе по односвязному списку возвращается найденная вершина.

```c++
list_node_t *hash_table_32b_find_key(hash_table_32b_t *hash_table, const char key_32b[]) {

    list_node_t *cur_node = hash_table->data[table_idx];
    while (cur_node) {
       if (strncmp(key_32b, cur_node->key, 32) == 0) return cur_node;

        cur_node = cur_node->next;
    }

    return NULL;
}
```





В данной работе исследуются приемы оптимизации хеш-таблицы, реализованной методом цепочек. Основная цель — выявить «горячие» участки кода с помощью профилирования и улучшить их производительность за счет использования низкоуровневых техник, таких как ассемблерные вставки, `intrinsics`, реализация функций на `nasm`.

Оптимизации будут проводиться итеративно. Каждая новая версия проекта будет включать в себя оптимизации предыдущей:
* `v1` - версия без оптимизаций
* `v2` - версия с оптимизациями компилятора
* `v3` - версия с intrinsic оптимизацией функции crc32
* `v4` - версия с использованием собственной реализацией функции streq на ассемблере
* `v5` - версия с использованием inline функции streq с ассемблерными вставками


## Входные данные
Перед началом тестирования хэш таблицы требуется сгенерировать входные данные. В качестве исходника для входных данных был взят текст романа Л. Н. Толстого "Война и мир", находящийся в файле `war_and_peace.txt`.

Подготовленными входными данными являются:
* Список слов для загрузки в хэш таблицу `text.txt`
* Список слов для тестирования хэш таблицы `tests.txt`

Для исследования оптимизаций хэш-таблицы установим:
* Длину каждого списка из входных данных в `40000` слов
* Размер хэш-таблицы в `512` ячеек

Данные константы были подобраны для того, чтобы `load factor` хэш-таблицы был равен `≈15`. В реальности данное значение `load factor` слишком велико и может привести к длительному линейному поиску в односвязном списке. В данной работе `load factor` был взят неоптимальным в учебных целях : для возможности применения эффективных оптимизации к функции `strncmp` и достоверного исследования хеш-функции на частоту коллизий.

Для генерации входных данных используйте команду:

```bash
    python3 run.py gen_tests
```

После выполнения команды будет создана папка `data` с файлами `text.txt` и `tests.txt` с необходимыми входными данными.



### Методика работы

## Среда
* __Процессор:__ Intel Core i5-10300H 2.5GHz
* __Оперативная память:__ 8Gb
* __Кэш память__
    * __L1__ : 256 Kb
    * __L2__ : 1 Mb
    * __L3__ : 8 Mb
* __Компилятор:__ g++ 13.3.0
* __Среда:__ Ubuntu 24.04

## Инструменты
* __Профилирование:__ perf, hotspot
* __Сборка:__ makefile, python

### Ход работы

#### 1. __Профилирование__

Профилирование выполняется с помощью `perf` с флагами:
```bash
perf record -g --call-graph dwarf -e branch-misses,cache-misses,instructions,cycles -T -F 100000 -- <исполняемый файл> <флаги исполняемого файла>
```

* Для увеличения количества `samples` рекомендуется добавить в <флаги исполняемого файла> : `--measures=100`
* `-g` - включает запись call graph для каждого семпла
* `--call-graph dwarf` - выбирает технологию `dwarf` сбора данных для `--call-graph`. При выборе `dwarf` `perf` дополнительно к исполняемой программе поддерживает стековую память самостоятельно. Эта технология имеет ограничение на глубину стека и требует больше ресурсов, __но__ позволяет анализировать программы, в которых в целях оптимизации не всегда создается стековый фрейм (см. `-fno-omit-frame-pointer`).
* `-T | --timestamp` - записывает временные метки (таймстемпы) для каждого семпла. Это позволяет в дальнейшем выводить точное время появления каждого события (например, с помощью perf report -D)
* `-F | --freq` - задаёт частоту семплирования — количество семплов в секунду

#### 2. __Анализ `perf hist`__

Для анализа `perf hist` используется команда
```bash
perf report --call-graph fractal,caller -i <путь до perf.data>
```

* fractal — формат, в котором проценты нормализуются относительно каждого родителя (каждая ветка дерева рассматривается отдельно). Используется этот формат, чтобы оценить влияние оптимизируемых функций только на измеряемую часть работы хэш-таблицы (`поиск`), а не на всю работу программы целиком.
* caller — порядок отображения "родитель → потомок"

#### 2. __Измерение времени работы версий:__

##### 2.1 __Разогрев (`Warm-up`):__

Перед основными измерениями выполняется серия холостых вызовов функции find_key для исключения влияния первого запуска и кэш-прогрева.

##### 2.2 __Основные замеры:__

Для каждой версии проекта выполняется несколько измерений времени выполнения всех операций `find_key` на тестах из входных данных.

Выставить длину серии холостых вызовов и количество измерений на каждую версию можно в `configs/benchmarks.yaml`. Для того, чтобы версии тестировались в наиболее приближенных условиях рекомендуется выставлять одинаковые значения в полях, отвечающих за количество измерений на каждую версию.

<img
  src="results/screenshots/runs.png"
  style="width: 70%; height: auto;"
/>

#### 3. __Обработка результатов__

Итоговые результаты бенчмаркинга генерируются с учетом погрешности ($x_{mean} \pm \sigma_{x_{mean}}$). Выбросы убираются по правилу $3‑σ$.
При расчете использовались формулы:

$$x_{mean} = \frac{\Sigma_{1}^{N}x_i}{n} $$

$$s = \sqrt{\frac{1}{N - 1}\Sigma_{1}^{N}(x_i - x_{mean})^2}$$

$$\sigma_{x_{mean}} = \frac{s}{\sqrt{N}}$$

Для запуска процесса измерения версий нужно написать команду:
```bash
python3 run.py vbench
```
После завершения работы скрипта в файле `results/versions_benchmarks` появятся результаты измерений версий. Рядом с каждым результатом измерений будет выведена информация об относительной погрешности:
`(error : XX.XX%)`.
Высокое значение `error` сигнализирует о возможной недостоверности измерений. Для уменьшения относительной погрешности рекомендуется увеличить значения в полях, отвечающих за количество измерений на каждую версию в файле `configs/benchmarks.yaml`.

## Исследование функций хэширования
Перед началом процесса оптимизации рассмотрим несколько хэш-функций и отберем самую лучшую.
Все хэш-функции имеют сигнатуру
```c++
uint64_t hash_function(const char key[]);
```
Выбор самой лучшей хэш-функции будет определятся несколькими критериями:
* __Величина стандартного распределения коллизий__. Чем меньше величина, тем равномернее будут распределяться значения по хэш-таблице, что будет способствовать ускорению поиска значений.
* __intrinsic Поддержка__. Для некоторых хэш-функций были созданы `intrinsics`, использование которых значительно ускоряет их работу.

### Хэш-функция : "Первый символ"

__Реализация__
```c++
uint64_t first_char_hash_func(const char key[]) {
    return (uint64_t) key[0];
}
```

__График коллизий__

<img
  src="results/hash_funcs/img/fchar.png"
  style="width: 50%; height: auto;"
/>

__Параметры__
|                        |        |
|------------------------|--------|
| Ticks                  | 161208 |
| Стандартное отклонение | 71.08  |

__Описание__

Функция не покрывает весь диапазон значений. Большинство значений приходятся на промежуток `[50, 130]`. Не смотря на свою большую скорость, функция неэффективна из-за плохого распределения своих значений.


### Хэш-функция : "Полиномиальная"
__Реализация__
```c++
uint64_t polynom_hash_func(const char key[]) {
    uint64_t hash = 0;
    uint64_t hash_mult = 255;
    uint64_t hash_mod = (uint64_t) 1e9 + 7;

    for (size_t i = 0; key[i]; i++) {
        hash = (hash * hash_mult + (uint64_t) key[i]) % hash_mod;
    }

    return hash;
}
```

__График коллизий__

<img
  src="results/hash_funcs/img/poly.png"
  style="width: 50%; height: auto;"
/>

__Параметры__
|                        |         |
|------------------------|---------|
| Ticks                  | 1120538 |
| Стандартное отклонение | 4.24    |

__Описание__

Функция достаточно хорошо покрывает весь диапазон значений, но ее она достаточно долго работает и ее дальнейшая оптимизация затруднительна.


### Хэш-функция : "FNV (Fowler–Noll–Vo)"

__Реализация__
```c++
uint64_t fnv1a_hash(const char key[]) {
    const uint64_t FNV_prime = 0x01000193;
    uint64_t hash = 0x811C9DC5;
    const uint8_t *bytes = (const uint8_t *) key;

    for (size_t i = 0; i < len; i++) {
        hash ^= bytes[i];
        hash *= FNV_prime;
    }
    return hash;
}
```

__График коллизий__

<img
  src="results/hash_funcs/img/fnv.png"
  style="width: 50%; height: auto;"
/>

__Параметры__
|                        |         |
|------------------------|---------|
| Ticks                  | 899462  |
| Стандартное отклонение | 3.95    |

__Описание__
Хорошая с точки зрения распределения хэш-функция. Работает достаточно быстро за счет простых битовых операций. Но ее оптимизационный потенциал меньше функции `crc32`, т.к. `FNV` не имеет прямой `intrinsic` поддержки.


### Хэш-функция : "crc32"

__Реализация__
```c++
uint64_t crc32_hash_func(char *key, const size_t len) {
    const uint64_t CRC32_POLY = 0x11EDC6F41;
    const unsigned char *buffer = (const unsigned char*) key;
    uint64_t crc = (uint64_t) -1;

    for (size_t i = 0; buffer[i]; i++) {
        crc = crc ^ (uint64_t) buffer[i];
        for(size_t j = 0; j < 8; j++) {
            crc = (crc >> 1) ^ (CRC32_POLY & (-(crc & 1)));
        }
    }

    return ~crc;
}
```

__График коллизий__

<img
  src="results/hash_funcs/img/crc32.png"
  style="width: 50%; height: auto;"
/>

__Параметры__
|                        |          |
|------------------------|----------|
| Ticks                  | 4177478  |
| Стандартное отклонение | 3.96     |

__Описание__
Обладает большим временем работы в сравнении с `FNV` функцией, но выигрывает за счет прямой поддержки `intrinsic`.

### Хэш-функция : "crc32_intrinsic"
Забегая немного вперед, покажу потенциал `intrinsic` реализации функции `crc32`, тем самым обосновав ее дальнейший выбор.


__Реализация__
```c++
uint64_t crc32_intrinsic_hash_func(const char key[], const size_t len __attribute__((unused))) {
    uint64_t res = 0;

    uint64_t key_vec_u64_0 = 0;
    uint64_t key_vec_u64_1 = 0;
    uint64_t key_vec_u64_2 = 0;
    uint64_t key_vec_u64_3 = 0;

    memcpy(&key_vec_u64_0, key + 0, 8);
    memcpy(&key_vec_u64_1, key + 1, 8);
    memcpy(&key_vec_u64_2, key + 2, 8);
    memcpy(&key_vec_u64_3, key + 3, 8);

    res = _mm_crc32_u64(res, key_vec_u64_0);
    res = _mm_crc32_u64(res, key_vec_u64_1);
    res = _mm_crc32_u64(res, key_vec_u64_2);
    res = _mm_crc32_u64(res, key_vec_u64_3);

    return res;
}
```

__График коллизий__

<img
  src="results/hash_funcs/img/crc32_intrinsic.png"
  style="width: 50%; height: auto;"
/>

__Параметры__
|                        |          |
|------------------------|----------|
| Ticks                  | 139262   |
| Стандартное отклонение | 4.37     |

__Описание__
Не смотря на более плохой показатель стандартного отклонения, чем у `FNV`, функция значительно превосходит ее по скорости. Также имеет более короткую реализацию, которая после оптимизации и вовсе развернется в 7 инструкций. Стоит заметить присутствие некой инструкции `endbr64` - она позволяет сделать на нее `indirect jump`, который используется т.к. тестируемые хэш-функции вызываются по указателю, который хранится в структуре хэш-таблицы.

<img
  src="results/screenshots/crc32_intrinsic_asm.png"
  style="width: 50%; height: auto;"
/>





## Итоговые результаты сравнения
Хэш функции были протестированы на входных данных с флагом компиляции `-O3`.

Хэш-функция         |   ticks   | стандартное отклонение
--------------------|-----------|-----------------------
fchar               | 161208    | 71.08
poly                | 1120538   | 4.24
fnv                 | 899462    | 3.95
crc32               | 4177478   | 3.96
crc32_intrinsic     | 139262    | 4.37


Эффективнее всего показала себя хэш-функция `crc32_intrinsic`. Поэтому в дальнейшем будем использовать именно ее.

## Оптимизации хэш-таблицы
Перед началом оптимизации хэш-таблицы ознакомимся с основными флагами для профилирования, которые я буду в дальнейшем использовать.

### Версия `v1`

`Compile flags:` `-O0 -march=native -D NDEBUG`

`Launch flags:` `--hash=crc32`

В учебных целях измерим время работы версии v1 несмотря на отсутствие компиляторных оптимизаций.


__Результаты__
Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -

Стартовая версия без оптимизаций. Специфика входных данных не учтена.
Вместо `crc32_intrinsic` выбрана хэш-функция `crc32`, чтобы при дальнейшем анализе показать, что неэффективная реализация хэш-функции может быть узким местом во всей программе.

__Perf hist__
![Perf hist для версии v1](/results/screenshots/perfhist_v1.png)

__Flame graph__
![Flame graph для версии v1](/results/screenshots/hotspot_v1.png)

__Промежуточный вывод__

Действительно, хэш-функция `crc32` оказалась самым узким местом программы. Согласно `perf hist` ее вклад в измерения составляет ≈$93$%


### Версия `v2`
`Compile flags :` `-O3 -march=native -mtune=native -D NDEBUG `

`Launch flags :` `--hash=crc32`
Отличие от предыдущей версии состоит в наличии стандартных оптимизаций, действующих при компиляции с флагами `-O3 -mtune=native`.

__Результаты__

Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -
v2	   | 5 991  ± 1	| 3	      | 1,69×

__Perf hist__
![Perf hist для версии v2](/results/screenshots/perfhist_v2.png)


При анализе ассемблерного кода после трансляции было замечено, что компилятор ускорил хэш-функцию `crc32`.
Изучим техники, примененные компилятором при данной оптимизации

__godbolt template__ : https://godbolt.org/z/8xsj9Mqz3

Первой техникой компилятора было сокращение работы с памятью. В ассемблерном коде `O0` наблюдается частое использование переменных, хранящихся на стековом фрейме в то время, как оптимизированная версия его не использует.
![сравнение O3 и O0 в godbolt](/results/screenshots/O3_crc32_opti_mem.png)

Второй техникой была развертка внутреннего цикла.
![O3 unroll godbolt](/results/screenshots/O3_unroll.png)


### Версия `v3`
`Compile flags :` `-O3 -march=native -mtune=native -D NDEBUG`

`Launch flags :` `--hash=crc32_intrinsic`

Не смотря на оптимизации компилятора, примененные в `v2`, хэш-функция `crc32` по-прежнему остается самым узким местом программы. В `v3` воспользуемся `intrinsic` реализацией функции `crc32`.

__Результаты__

Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -
v2	   | 5 991  ± 1	| 3	      | 1,69×
v3	   | 2 522  ± 9 | 3	      | 2,38×

__Perf hist__
![Perf hist для версии v3](/results/screenshots/v3perfhist.png)


Анализ `perf hist` показал, что примененная оптимизация дала __ощутимый эффект__: `crc32` стала занимать всего `2.34% overhead`. Теперь стандартная функция `strncmp_avx2` является узким местом программы с `56.89% overhead`.

### Версия `v4`
`Compile_flags :` `-O3 -march=native -mtune=native -D MY_STREQ -D NDEBUG`

`Launch_flags :` `--hash=crc32_intrinsic`

Напишем свою функцию `streq_32b` на ассемблере и воспользуемся ею в текущей версии.
Реализация `streq_32b` опиралась на специфику входных данных (все слова имеют длину <= 32). В ней строки загружаются в вектора `ymm` по 256 байт и сравниваются одной ассемблерной инструкцией `vpcmpeqb`.

> [!Warning]
> Для корректной работы функции `streq` строки должны быть выравнены по 32 байта, т.к. в реализации функции используется инструкция `vmovdqa`, работающая исключительно с выравненными по 32 байта данными.


__Реализация__
```nasm
global streq_32b

section .text

streq_32b:
    vmovdqa ymm0, [rdi]
    xor rax, rax
    vptest ymm0, [rsi]
    seta al

    ret
```

__Результаты__
Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -
v2	   | 5 991  ± 1	| 3	      | 1,69×
v3	   | 2 522  ± 9 | 3	      | 2,38×
v4	   | 1 577  ± 9 | 3	      | 1,60×

__Perf hist__
![Perf hist для версии v4](/results/screenshots/v4streq.png)

Было получено глобальное ускорение функции сравнения строк более чем на `8%`. Но несмотря на это, она по-прежнему остается самой горячей. Попробуем исправить это в следующей версии.

### Версия `v5`

`Compile flags :` `-O3 -march=native -mtune=native -masm=intel -D INLINE_ASM_STREQ -D NDEBUG`
`Launch flags :` `--hash=crc32_intrinsic`

Реализую inline версию функции `streq_32b` с помощью ассемблерных вставок.



__Реализация__
```c++
__attribute__((unused))
inline int streq_32b_inline(const char *str1, const char *str2) {
    int res = 0;
    __asm__(".intel_syntax noprefix\n"
            "vmovdqa ymm0, [%1]\n"
            "xor rax, rax\n"
            "vptest ymm0, [%2]\n"
            "seta al\n"

            : "=a"(res)
            : "r"(str1),
              "D"(str2)
            : "ymm0", "cc");

    return res;
}
```
В `perf annotate` видно, что произошел `inlining` функции `streq`.

![inline streq реализация](/results/screenshots/inlinestreq.png)

__Результаты__
Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -
v2	   | 5 991  ± 1	| 3	      | 1,69×
v3	   | 2 522  ± 9 | 3	      | 2,38×
v4	   | 1 577  ± 9 | 3	      | 1,60×
v5	   | 1 551  ± 7 | 3	      | 1,02×

`Inline streq` дала незначительный прирост к скорости `2%`, поэтому было принято решение закончить цепочку оптимизаций.


# Заключение

## Итоговые результаты:
Версия | Ticks  (средн. ± σ)  | Порядок | Ускорение относительно предыдущей версии
-------|------------|---------|-------
v1	   | 1014   ± 2	| 4       | -
v2	   | 5 991  ± 1	| 3	      | 1,69×
v3	   | 2 522  ± 9 | 3	      | 2,38×
v4	   | 1 577  ± 9 | 3	      | 1,60×
v5	   | 1 551  ± 7 | 3	      | 1,02×

Итого, итоговая версия `v5` имеет ускорение в `3.86` раза относительно версии `v2`.


После процесса последовательных оптимизаций работа с хеш-таблицей была ускорена в `3.86` раз. Было продемонстрировано, что при должном понимании ограничений на входные данные появляется возможность проводить более агрессивные оптимизации, которые не может себе позволить компилятор. Также был показан ощутимый эффект применения ассемблерных оптимизаций.

В образовательных целях мы пренебрегли очень важным фактором скорости работы хеш-таблицы, ее `load factor`.
Но реальных проектах перед началом ассемблерных оптимизаций очень важно провести алгоритмический анализ. Ведь некоторые узкие в алгоритмическом смысле места могут быть нераспознаны к примеру профилировщиком.
